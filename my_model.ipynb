{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d50b3a8",
   "metadata": {},
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8565eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ibrah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import os   # Importing the os module to interact with the operating system and manage file paths and directories\n",
    "import pandas as pd     # Importing pandas for data manipulation\n",
    "from sklearn.model_selection import train_test_split    # Importing train_test_split from sklearn for splitting the data into training and validation sets\n",
    "\n",
    "# Importing the BERT tokenizer to convert text reviews into token IDs suitable for BERT\n",
    "# Importing AdamW as the optimizer for training BERT models, which includes weight decay for regularization\n",
    "from transformers import BertTokenizer, AdamW\n",
    "\n",
    "import torch        # Importing torch, the core library for deep learning in PyTorch\n",
    "print(torch.__version__)    # Print the version of PyTorch being used for this project\n",
    "\n",
    "# Importing necessary classes from PyTorch to handle data batching and sampling\n",
    "# DataLoader: Used to load batches of data during training and evaluation\n",
    "# TensorDataset: Converts input features and labels into tensors that can be processed by the model\n",
    "# RandomSampler: Randomly samples data (typically for training) to introduce randomness and reduce overfitting\n",
    "# SequentialSampler: Samples data sequentially (typically for evaluation) without shuffling\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55fc937",
   "metadata": {},
   "source": [
    "#### Check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26f2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.cuda.device_count())  # Should be > 0 if CUDA is enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59dae0c",
   "metadata": {},
   "source": [
    "#### Load train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a050ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought this belt for my daughter in-law for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The size was perfect and so was the color.  It...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fits and feels good, esp. for doing a swim rac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These socks are absolutely the best. I take pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you so much for the speedy delivery they...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiments\n",
       "0  I bought this belt for my daughter in-law for ...           1\n",
       "1  The size was perfect and so was the color.  It...           1\n",
       "2  Fits and feels good, esp. for doing a swim rac...           1\n",
       "3  These socks are absolutely the best. I take pi...           1\n",
       "4  Thank you so much for the speedy delivery they...           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data from a JSON file into a pandas DataFrame\n",
    "train_df = pd.read_json('Data Samples/train.json')\n",
    "\n",
    "# Print the shape of the DataFrame to display the number of rows and columns\n",
    "print(train_df.shape)\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the contents and structure of the dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a96201",
   "metadata": {},
   "source": [
    "#### We first need to tokenize the reviews and prepare the data for BERT. \n",
    "##### BERT expects tokenized input in the form of input IDs, attention masks, and possibly token type IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67f041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Preprocess the reviews\n",
    "def encode_reviews(reviews, tokenizer, max_length=256):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        reviews, \n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        return_attention_mask=True,  # Return attention masks\n",
    "        padding='max_length',  # Pad to max_length\n",
    "        truncation=True,  # Truncate longer sequences\n",
    "        max_length=max_length,  # Maximum length of sequences\n",
    "        return_tensors='pt'  # Return PyTorch tensors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f9508",
   "metadata": {},
   "source": [
    "#### Encode reviews and Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d28e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = encode_reviews(train_df['reviews'].tolist(), tokenizer)\n",
    "\n",
    "# Step 1: Prepare Labels\n",
    "labels = torch.tensor(train_df['sentiments'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf4af4",
   "metadata": {},
   "source": [
    "#### Step 2: Split Data into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d401db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split Data into Training and Validation Sets\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    train_encodings['input_ids'], labels, test_size=0.1, random_state=42\n",
    ")\n",
    "train_masks, val_masks, _, _ = train_test_split(\n",
    "    train_encodings['attention_mask'], labels, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35419556",
   "metadata": {},
   "source": [
    "#### Step 3: Create DataLoaders for Efficient Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c61d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create DataLoaders for Efficient Batching\n",
    "batch_size = 16 # Set the batch size, which determines how many samples are processed in each batch\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb92fd",
   "metadata": {},
   "source": [
    "#### Import the DistilBERT model and set the number of labels\n",
    "\n",
    "`https://huggingface.co/docs/transformers/model_doc/distilbert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc4c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the DistilBERT model for sequence classification from the transformers library\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased', \n",
    "    \n",
    "    # Binary classification (0 for negative sentiment, 1 for positive sentiment)\n",
    "    num_labels=2\n",
    ")\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f8dd7",
   "metadata": {},
   "source": [
    "#### Step 5: Set Up Optimizer and Training Loop\n",
    "\n",
    "##### Set the number of epochs according to the size of your dataset.\n",
    "##### For example, \n",
    "##### - Small Datasets (Typically around 1,000 to 10,000 samples): 3-5\n",
    "##### - Medium to Large Datasets (Typically around 10,000 to 500,000 samples): 2-3\n",
    "##### - Very Large Datasets (Typically 500,000 samples or more): 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a036d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ibrah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Average training loss for epoch 1: 0.21\n",
      "Validation loss for epoch 1: 0.14\n",
      "Starting epoch 2\n",
      "Average training loss for epoch 2: 0.09\n",
      "Validation loss for epoch 2: 0.15\n",
      "Starting epoch 3\n",
      "Average training loss for epoch 3: 0.04\n",
      "Validation loss for epoch 3: 0.21\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Set Up Optimizer and Training Loop\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)    # AdamW is an optimization algorithm, widely used for training transformer-based models like BERT\n",
    "\n",
    "# Training Loop\n",
    "epochs = 3  # Number of training epochs, i.e., how many times the entire training dataset is passed through the model\n",
    "            # Adjust this value to change the number of iterations the model will train for\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Starting epoch {epoch + 1}\")\n",
    "    \n",
    "    # Set the model to training mode (enables features like dropout)\n",
    "    model.train()\n",
    "\n",
    "    # Variable to accumulate total training loss for this epoch\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "\n",
    "        # Move the input tensors (input IDs, attention masks, and labels) to the GPU (if available) or CPU\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t.to('cuda' if torch.cuda.is_available() else 'cpu') for t in batch)\n",
    "\n",
    "        # Zero out any previously accumulated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass: Compute model outputs (predictions and loss)\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss     # Extract the loss value from the model's output\n",
    "        total_train_loss += loss.item()     # Add the loss value to the running total\n",
    "        \n",
    "        # Backward pass: Compute the gradients of the loss with respect to the model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model parameters using the gradients calculated during the backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the average training loss for the epoch\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss for epoch {epoch + 1}: {avg_train_loss:.2f}\")\n",
    "\n",
    "    # Validation\n",
    "    # Set the model to evaluation mode (disables dropout and other training-specific operations)\n",
    "    model.eval()\n",
    "\n",
    "    # Variable to accumulate total validation loss for this epoch\n",
    "    total_val_loss = 0\n",
    "\n",
    "    # Disable gradient calculations to save memory during the validation step\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to('cuda' if torch.cuda.is_available() else 'cpu') for t in batch)\n",
    "\n",
    "            # Forward pass for validation: Compute model outputs and loss without computing gradients\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    # Calculate the average validation loss for the epoch\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    print(f\"Validation loss for epoch {epoch + 1}: {avg_val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7d257",
   "metadata": {},
   "source": [
    "#### Save the model into the 'Models' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b29e2452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'Models' folder already exists.\n",
      "The model file 'Models\\bert_sentiment_model.pt' already exists. It will be updated.\n",
      "The tokenizer configuration at 'Models\\tokenizer' already exists. It will be updated.\n",
      "Model has been saved to Models\\bert_sentiment_model.pt\n",
      "Tokenizer has been saved to Models\\tokenizer\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create the \"Models\" folder if it doesn't exist\n",
    "if not os.path.exists('Models'):\n",
    "    os.makedirs('Models')\n",
    "    print(\"The 'Models' folder has been created.\")\n",
    "else:\n",
    "    print(\"The 'Models' folder already exists.\")\n",
    "\n",
    "# Step 7: Define the path for saving the model\n",
    "model_save_path = os.path.join('Models', 'bert_sentiment_model.pt')\n",
    "\n",
    "# Check if the model file already exists\n",
    "if os.path.exists(model_save_path):\n",
    "    print(f\"The model file '{model_save_path}' already exists. It will be updated.\")\n",
    "else:\n",
    "    print(f\"The model file '{model_save_path}' does not exist and will be created.\")\n",
    "\n",
    "# Step 8: Save the model's state dictionary\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# Optional: Save the tokenizer configuration if needed for reloading the model\n",
    "tokenizer_save_path = os.path.join('Models', 'tokenizer')\n",
    "\n",
    "# Check if the tokenizer directory already exists\n",
    "if os.path.exists(tokenizer_save_path):\n",
    "    print(f\"The tokenizer configuration at '{tokenizer_save_path}' already exists. It will be updated.\")\n",
    "else:\n",
    "    print(f\"The tokenizer configuration at '{tokenizer_save_path}' does not exist and will be created.\")\n",
    "    \n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "# Confirmation message\n",
    "print(f\"Model has been saved to {model_save_path}\")\n",
    "print(f\"Tokenizer has been saved to {tokenizer_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106a1e8",
   "metadata": {},
   "source": [
    "### Now we can apply this model onto our test data samples (test.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414455c3",
   "metadata": {},
   "source": [
    "#### Load the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f658ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1851, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought 2 sleepers.  sleeper had holes in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dare say these are just about the sexiest th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everything about the transaction (price, deliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not bad for just a shirt.  Very durable, and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These are truly wrinkle free and longer than t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  I bought 2 sleepers.  sleeper had holes in the...\n",
       "1  I dare say these are just about the sexiest th...\n",
       "2  everything about the transaction (price, deliv...\n",
       "3  Not bad for just a shirt.  Very durable, and m...\n",
       "4  These are truly wrinkle free and longer than t..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json('Data Samples/test.json')\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990b1ea",
   "metadata": {},
   "source": [
    "#### Import the necessary functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1673ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary functions for model evaluation\n",
    "# classification_report provides a detailed report on precision, recall, and F1-score for each class\n",
    "# accuracy_score calculates the overall accuracy of the model.\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "\n",
    "# Step 1: Preprocess Test Data\n",
    "test_encodings = encode_reviews(test_df['reviews'].tolist(), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a884251",
   "metadata": {},
   "source": [
    "#### Prepare the Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd5034fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the Test DataLoader\n",
    "test_inputs = test_encodings['input_ids']\n",
    "test_masks = test_encodings['attention_mask']\n",
    "test_data = TensorDataset(test_inputs, test_masks)\n",
    "\n",
    "# Use SequentialSampler for the test data (no shuffling needed)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6916d717",
   "metadata": {},
   "source": [
    "#### Step 4: Make Predictions on the Test Set by running the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8420a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviews  sentiments\n",
      "0  I bought 2 sleepers.  sleeper had holes in the...           0\n",
      "1  I dare say these are just about the sexiest th...           1\n",
      "2  everything about the transaction (price, deliv...           1\n",
      "3  Not bad for just a shirt.  Very durable, and m...           1\n",
      "4  These are truly wrinkle free and longer than t...           1\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Make Predictions on the Test Set\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "# Run the model on the test data\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids, b_input_mask = tuple(t.to('cuda' if torch.cuda.is_available() else 'cpu') for t in batch)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the predicted sentiment (0 or 1 for binary classification)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Step 5: Add the Predicted Sentiments to the DataFrame\n",
    "test_df['sentiments'] = predictions\n",
    "\n",
    "# View the predictions with the reviews\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b41c79",
   "metadata": {},
   "source": [
    "#### Now that the predictions have been made, we can export this to a csv file for review analysis\n",
    "#### Create the `submission.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04afc8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'Results' folder already exists.\n",
      "The file 'submission.csv' already exists. It will be updated with new data.\n",
      "Predictions have been saved to Results\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create the \"Results\" folder if it doesn't exist\n",
    "if not os.path.exists('Results'):\n",
    "    os.makedirs('Results')\n",
    "    print(\"The 'Results' folder has been created.\")\n",
    "else:\n",
    "    print(\"The 'Results' folder already exists.\")\n",
    "\n",
    "# Step 7: Save the test dataframe with predictions to 'submission.csv'\n",
    "submission_file = os.path.join('Results', 'submission.csv')\n",
    "\n",
    "# Check if the submission file already exists\n",
    "if os.path.exists(submission_file):\n",
    "    print(\"The file 'submission.csv' already exists. It will be updated with new data.\")\n",
    "else:\n",
    "    print(\"The file 'submission.csv' does not exist and will be created.\")\n",
    "    \n",
    "test_df.to_csv(submission_file, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Predictions have been saved to {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203790ad",
   "metadata": {},
   "source": [
    "#### If you would like to reload the saved model and tokenizer for inference or fine-tuning on another dataset, use the following code (Select All and Uncomment). \n",
    "#### This will load the model weights from the saved state dictionary and configure the tokenizer to match the settings used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58d5de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Define paths to the model and tokenizer\n",
    "# model_load_path = 'Models/bert_sentiment_model.pt'\n",
    "# tokenizer_load_path = 'Models/tokenizer'\n",
    "\n",
    "# # Step 2: Check if model and tokenizer paths exist, and load them if available\n",
    "# if os.path.exists(model_load_path) and os.path.exists(tokenizer_load_path):\n",
    "#     print(\"Found model and tokenizer files. Proceeding to load them.\")\n",
    "    \n",
    "#     # Reload the tokenizer from the saved configuration\n",
    "#     tokenizer = BertTokenizer.from_pretrained(tokenizer_load_path)\n",
    "#     print(\"Tokenizer loaded successfully.\")\n",
    "    \n",
    "#     # Step 3: Reload the model with the same architecture and load the saved state\n",
    "#     model = DistilBertForSequenceClassification.from_pretrained(\n",
    "#         'distilbert-base-uncased', \n",
    "#         num_labels=2\n",
    "#     )\n",
    "    \n",
    "#     # Load the state dictionary into the model\n",
    "#     model.load_state_dict(torch.load(model_load_path))\n",
    "#     print(\"Model loaded successfully.\")\n",
    "    \n",
    "#     # Step 4: Send the model to GPU if available\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Set the model to evaluation mode (disables dropout layers)\n",
    "#     model.eval()\n",
    "    \n",
    "#     print(\"Model and tokenizer successfully loaded for inference.\")\n",
    "# else:\n",
    "#     if not os.path.exists(model_load_path):\n",
    "#         print(f\"Model file '{model_load_path}' not found.\")\n",
    "#     if not os.path.exists(tokenizer_load_path):\n",
    "#         print(f\"Tokenizer configuration '{tokenizer_load_path}' not found.\")\n",
    "#     print(\"Please ensure both model and tokenizer files are available in the 'Models' folder before running this code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
