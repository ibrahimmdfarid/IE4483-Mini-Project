{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d50b3a8",
   "metadata": {},
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd     # Importing pandas for data manipulation\n",
    "from sklearn.model_selection import train_test_split    # Importing train_test_split from sklearn for splitting the data into training and validation sets\n",
    "\n",
    "# Importing the BERT tokenizer to convert text reviews into token IDs suitable for BERT\n",
    "# Importing AdamW as the optimizer for training BERT models, which includes weight decay for regularization\n",
    "from transformers import BertTokenizer, AdamW\n",
    "\n",
    "import torch        # Importing torch, the core library for deep learning in PyTorch\n",
    "print(torch.__version__)    # Print the version of PyTorch being used for this project\n",
    "\n",
    "# Importing necessary classes from PyTorch to handle data batching and sampling\n",
    "# DataLoader: Used to load batches of data during training and evaluation\n",
    "# TensorDataset: Converts input features and labels into tensors that can be processed by the model\n",
    "# RandomSampler: Randomly samples data (typically for training) to introduce randomness and reduce overfitting\n",
    "# SequentialSampler: Samples data sequentially (typically for evaluation) without shuffling\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55fc937",
   "metadata": {},
   "source": [
    "#### Check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.cuda.device_count())  # Should be > 0 if CUDA is enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59dae0c",
   "metadata": {},
   "source": [
    "#### Load train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a050ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought this belt for my daughter in-law for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The size was perfect and so was the color.  It...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fits and feels good, esp. for doing a swim rac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These socks are absolutely the best. I take pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you so much for the speedy delivery they...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiments\n",
       "0  I bought this belt for my daughter in-law for ...           1\n",
       "1  The size was perfect and so was the color.  It...           1\n",
       "2  Fits and feels good, esp. for doing a swim rac...           1\n",
       "3  These socks are absolutely the best. I take pi...           1\n",
       "4  Thank you so much for the speedy delivery they...           1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data from a JSON file into a pandas DataFrame\n",
    "train_df = pd.read_json('Data Samples/train.json')\n",
    "\n",
    "# Print the shape of the DataFrame to display the number of rows and columns\n",
    "print(train_df.shape)\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the contents and structure of the dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a96201",
   "metadata": {},
   "source": [
    "#### We first need to tokenize the reviews and prepare the data for BERT. \n",
    "##### BERT expects tokenized input in the form of input IDs, attention masks, and possibly token type IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a67f041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Preprocess the reviews\n",
    "def encode_reviews(reviews, tokenizer, max_length=256):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        reviews, \n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        return_attention_mask=True,  # Return attention masks\n",
    "        padding='max_length',  # Pad to max_length\n",
    "        truncation=True,  # Truncate longer sequences\n",
    "        max_length=max_length,  # Maximum length of sequences\n",
    "        return_tensors='pt'  # Return PyTorch tensors\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f9508",
   "metadata": {},
   "source": [
    "#### Encode reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d28e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = encode_reviews(train_df['reviews'].tolist(), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c7ef4",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb53edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Labels\n",
    "labels = torch.tensor(train_df['sentiments'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf4af4",
   "metadata": {},
   "source": [
    "#### Step 2: Split Data into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d401db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split Data into Training and Validation Sets\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    train_encodings['input_ids'], labels, test_size=0.1, random_state=42\n",
    ")\n",
    "train_masks, val_masks, _, _ = train_test_split(\n",
    "    train_encodings['attention_mask'], labels, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35419556",
   "metadata": {},
   "source": [
    "#### Step 3: Create DataLoaders for Efficient Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c61d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create DataLoaders for Efficient Batching\n",
    "batch_size = 16 # Set the batch size, which determines how many samples are processed in each batch\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb92fd",
   "metadata": {},
   "source": [
    "#### Import the DistilBERT model and set the number of labels\n",
    "\n",
    "`https://huggingface.co/docs/transformers/model_doc/distilbert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the DistilBERT model for sequence classification from the transformers library\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased', \n",
    "    \n",
    "    # Binary classification (0 for negative sentiment, 1 for positive sentiment)\n",
    "    num_labels=2\n",
    ")\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f8dd7",
   "metadata": {},
   "source": [
    "#### Step 5: Set Up Optimizer and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1: 0.21\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Set Up Optimizer and Training Loop\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)    # AdamW is an optimization algorithm, widely used for training transformer-based models like BERT\n",
    "\n",
    "# Training Loop\n",
    "epochs = 1  # Number of training epochs, i.e., how many times the entire training dataset is passed through the model\n",
    "            # Adjust this value to change the number of iterations the model will train for\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Set the model to training mode (enables features like dropout)\n",
    "    model.train()\n",
    "\n",
    "    # Variable to accumulate total training loss for this epoch\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "\n",
    "        # Move the input tensors (input IDs, attention masks, and labels) to the GPU (if available) or CPU\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t.to('cuda' if torch.cuda.is_available() else 'cpu') for t in batch)\n",
    "\n",
    "        # Zero out any previously accumulated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass: Compute model outputs (predictions and loss)\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss     # Extract the loss value from the model's output\n",
    "        total_train_loss += loss.item()     # Add the loss value to the running total\n",
    "        \n",
    "        # Backward pass: Compute the gradients of the loss with respect to the model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model parameters using the gradients calculated during the backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the average training loss for the epoch\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss for epoch {epoch + 1}: {avg_train_loss:.2f}\")\n",
    "\n",
    "    # Validation\n",
    "    # Set the model to evaluation mode (disables dropout and other training-specific operations)\n",
    "    model.eval()\n",
    "\n",
    "    # Variable to accumulate total validation loss for this epoch\n",
    "    total_val_loss = 0\n",
    "\n",
    "    # Disable gradient calculations to save memory during the validation step\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to('cuda' if torch.cuda.is_available() else 'cpu') for t in batch)\n",
    "\n",
    "            # Forward pass for validation: Compute model outputs and loss without computing gradients\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    # Calculate the average validation loss for the epoch\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    print(f\"Validation loss for epoch {epochs + 1}: {avg_val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106a1e8",
   "metadata": {},
   "source": [
    "### Now we can apply this model onto our test data samples (test.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414455c3",
   "metadata": {},
   "source": [
    "#### Load the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f658ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1851, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought 2 sleepers.  sleeper had holes in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dare say these are just about the sexiest th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everything about the transaction (price, deliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not bad for just a shirt.  Very durable, and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These are truly wrinkle free and longer than t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  I bought 2 sleepers.  sleeper had holes in the...\n",
       "1  I dare say these are just about the sexiest th...\n",
       "2  everything about the transaction (price, deliv...\n",
       "3  Not bad for just a shirt.  Very durable, and m...\n",
       "4  These are truly wrinkle free and longer than t..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json('Data Samples/test.json')\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990b1ea",
   "metadata": {},
   "source": [
    "#### Import the necessary functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary functions for model evaluation\n",
    "# classification_report provides a detailed report on precision, recall, and F1-score for each class\n",
    "# accuracy_score calculates the overall accuracy of the model.\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "\n",
    "# Step 1: Preprocess Test Data\n",
    "test_encodings = encode_reviews(test_df['reviews'].tolist(), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a884251",
   "metadata": {},
   "source": [
    "#### Step 3: Prepare the Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd5034fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the Test DataLoader\n",
    "test_inputs = test_encodings['input_ids']\n",
    "test_masks = test_encodings['attention_mask']\n",
    "test_data = TensorDataset(test_inputs, test_masks)\n",
    "\n",
    "# Use SequentialSampler for the test data (no shuffling needed)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6916d717",
   "metadata": {},
   "source": [
    "#### Step 4: Make Predictions on the Test Set by running the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8420a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviews  sentiments\n",
      "0  I bought 2 sleepers.  sleeper had holes in the...           0\n",
      "1  I dare say these are just about the sexiest th...           1\n",
      "2  everything about the transaction (price, deliv...           1\n",
      "3  Not bad for just a shirt.  Very durable, and m...           1\n",
      "4  These are truly wrinkle free and longer than t...           1\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Make Predictions on the Test Set\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "# Run the model on the test data\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids, b_input_mask = tuple(t.to('cuda' if torch.cuda.is_available() else 'cpu') for t in batch)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the predicted sentiment (0 or 1 for binary classification)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Step 5: Add the Predicted Sentiments to the DataFrame\n",
    "test_df['sentiments'] = predictions\n",
    "\n",
    "# View the predictions with the reviews\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b41c79",
   "metadata": {},
   "source": [
    "#### Now that the predictions have been made, we can export this to a csv file for review analysis\n",
    "#### Create the `submission.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afc8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been saved to Results\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Importing the os module to interact with the operating system and manage file paths and directories\n",
    "import os\n",
    "\n",
    "# Step 6: Create the \"Results\" folder if it doesn't exist\n",
    "if not os.path.exists('Results'):\n",
    "    os.makedirs('Results')\n",
    "\n",
    "# Step 7: Save the test dataframe with predictions to 'submission.csv'\n",
    "submission_file = os.path.join('Results', 'submission.csv')\n",
    "test_df.to_csv(submission_file, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Predictions have been saved to {submission_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
